{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad37069-2a81-4810-9d15-0f5a3e8e8190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from rich import print\n",
    "from sklearn.metrics import precision_score, recall_score, mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8cdcc0-520c-4f09-af0e-ed8b5f29c131",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GenomicTokenizer:\n",
    "    def __init__(self, ngram=5, stride=2):\n",
    "        self.ngram = ngram\n",
    "        self.stride = stride\n",
    "        \n",
    "    def tokenize(self, t):\n",
    "        t = t.upper()\n",
    "        if self.ngram == 1:\n",
    "            toks = list(t)\n",
    "        else:\n",
    "            toks = [t[i:i+self.ngram] for i in range(0, len(t), self.stride) if len(t[i:i+self.ngram]) == self.ngram]\n",
    "        if len(toks[-1]) < self.ngram:\n",
    "            toks = toks[:-1]\n",
    "        return toks\n",
    "\n",
    "\n",
    "class GenomicVocab:\n",
    "    def __init__(self, itos):\n",
    "        self.itos = itos\n",
    "        self.stoi = {v:k for k,v in enumerate(self.itos)}\n",
    "        \n",
    "    @classmethod\n",
    "    def create(cls, tokens, max_vocab, min_freq):\n",
    "        freq = Counter(tokens)\n",
    "        itos = ['<pad>'] + [o for o,c in freq.most_common(max_vocab-1) if c >= min_freq]\n",
    "        return cls(itos)\n",
    "\n",
    "\n",
    "class SiRNADataset(Dataset):\n",
    "    def __init__(self, df, columns, vocab, tokenizer, max_len):\n",
    "        self.df = df\n",
    "        self.columns = columns\n",
    "        self.vocab = vocab\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        seqs = [self.tokenize_and_encode(row[col]) for col in self.columns]\n",
    "        target = torch.tensor(row['mRNA_remaining_pct'], dtype=torch.float)\n",
    "\n",
    "        return seqs, target\n",
    "\n",
    "    def tokenize_and_encode(self, seq):\n",
    "        if ' ' in seq:  # Modified sequence\n",
    "            tokens = seq.split()\n",
    "        else:  # Regular sequence\n",
    "            tokens = self.tokenizer.tokenize(seq)\n",
    "        \n",
    "        encoded = [self.vocab.stoi.get(token, 0) for token in tokens]  # Use 0 (pad) for unknown tokens\n",
    "        padded = encoded + [0] * (self.max_len - len(encoded))\n",
    "        return torch.tensor(padded[:self.max_len], dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9781f900-0f79-4e73-8381-23b49b0ef3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SiRNAModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=200, hidden_dim=256, n_layers=3, dropout=0.5):\n",
    "        super(SiRNAModel, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.gru = nn.GRU(embed_dim, hidden_dim, n_layers, bidirectional=True, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 4, 1) # Bi-direactional and two feature columns\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embedded = [self.embedding(seq) for seq in x]\n",
    "        outputs = []\n",
    "        for embed in embedded:\n",
    "            x, _ = self.gru(embed)\n",
    "            x = self.dropout(x[:, -1, :])  # Use last hidden state\n",
    "            outputs.append(x)\n",
    "        \n",
    "        x = torch.cat(outputs, dim=1)\n",
    "        x = self.fc(x)\n",
    "        return x.squeeze()\n",
    "\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, threshold=30):\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "    y_true_binary = (y_true < threshold).astype(int)\n",
    "    y_pred_binary = (y_pred < threshold).astype(int)\n",
    "\n",
    "    mask = (y_pred >= 0) & (y_pred <= threshold)\n",
    "    range_mae = mean_absolute_error(y_true[mask], y_pred[mask]) if mask.sum() > 0 else 100\n",
    "\n",
    "    precision = precision_score(y_true_binary, y_pred_binary, average='binary')\n",
    "    recall = recall_score(y_true_binary, y_pred_binary, average='binary')\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    score = (1 - mae / 100) * 0.5 + (1 - range_mae / 100) * f1 * 0.5\n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=50, device='cuda'):\n",
    "    model.to(device)\n",
    "    best_score = -float('inf')\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for inputs, targets in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "            inputs = [x.to(device) for x in inputs]\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_preds = []\n",
    "        val_targets = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs = [x.to(device) for x in inputs]\n",
    "                targets = targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "                val_preds.extend(outputs.cpu().numpy())\n",
    "                val_targets.extend(targets.cpu().numpy())\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        val_preds = np.array(val_preds)\n",
    "        val_targets = np.array(val_targets)\n",
    "        score = calculate_metrics(val_targets, val_preds)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print(f'Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "        print(f'Learning Rate: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "        print(f'Validation Score: {score:.4f}')\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_model = model.state_dict().copy()\n",
    "            print(f'New best model found with socre: {best_score:.4f}')\n",
    "\n",
    "    return best_model\n",
    "\n",
    "def evaluate_model(model, test_loader, device='cuda'):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, target in test_loader:\n",
    "            inputs = [x.to(device) for x in inputs]\n",
    "            outputs = model(inputs)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            targets.extend(target.numpy())\n",
    "\n",
    "    y_pred = np.array(predictions)\n",
    "    y_test = np.array(targets)\n",
    "    \n",
    "    score = calculate_metrics(y_test, y_pred)\n",
    "    print(f\"Test Score: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777a69f5-a808-48bf-a3fc-2be22197b56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Load data\n",
    "train_data = pd.read_csv('../data/train_data.csv')\n",
    "columns = ['siRNA_antisense_seq', 'modified_siRNA_antisense_seq_list']\n",
    "\n",
    "train_data.dropna(subset=columns + ['mRNA_remaining_pct'], inplace=True)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.1, random_state=42)\n",
    "\n",
    "# Create vocabulary\n",
    "tokenizer = GenomicTokenizer(ngram=3, stride=1)\n",
    "\n",
    "all_tokens = []\n",
    "for col in columns:\n",
    "    for seq in train_data[col]:\n",
    "        if ' ' in seq:  # Modified sequence\n",
    "            all_tokens.extend(seq.split())\n",
    "        else:\n",
    "            all_tokens.extend(tokenizer.tokenize(seq))\n",
    "vocab = GenomicVocab.create(all_tokens, max_vocab=10000, min_freq=1)\n",
    "\n",
    "# Find max sequence length (==25 in this case)\n",
    "max_len = max(max(len(seq.split()) if ' ' in seq else len(tokenizer.tokenize(seq)) \n",
    "                    for seq in train_data[col]) for col in columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c48dfb-a537-4042-b770-c07f3bec0846",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load trained GRU model\n",
    "gru_model = SiRNAModel(92)\n",
    "gru_model.load_state_dict(torch.load('../data/gru_weights')) # Trained GRU model\n",
    "gru_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c954d3-d17d-4a54-8380-094fb45b1be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_original = pd.read_csv(\"../data/train_data.csv\")\n",
    "n_original = df_original.shape[0]\n",
    "df_submit = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "df = pd.concat([df_original, df_submit], axis=0).reset_index(drop=True)\n",
    "\n",
    "all_dataset = SiRNADataset(df, columns, vocab, tokenizer, max_len)\n",
    "all_loader = DataLoader(all_dataset, batch_size=df.shape[0], shuffle=False)\n",
    "for x, y in all_loader:\n",
    "    None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ff4c59-822b-4932-be96-9330654ffe6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "def get_GRU_output(x, model):\n",
    "    model.eval()\n",
    "    temp1 = model._modules['embedding'](x[0])\n",
    "    temp2 = model._modules['embedding'](x[1])\n",
    "    temp1, _ = model._modules['gru'](temp1)\n",
    "    temp2, _ = model._modules['gru'](temp2)\n",
    "    retval = torch.cat([temp1[:, -1, :], temp2[:, -1, :]], dim=1)\n",
    "    return retval\n",
    "\n",
    "gru_feature_1 = np.zeros((df.shape[0], 1024))\n",
    "gru_feature_2 = np.zeros((df.shape[0], 1))\n",
    "\n",
    "for i in range(0, len(y), 100):\n",
    "    with torch.no_grad():\n",
    "        temp_x = [x[0][i:(i+100)], x[1][i:(i+100)]]\n",
    "        gru_feature_2[i:(i+100),0] = gru_model(temp_x)\n",
    "        temp = get_GRU_output(temp_x, gru_model)\n",
    "        gru_feature_1[i:(i+100)] = np.array(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e596c4-7ca7-4e95-9909-726b65341fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_feature = np.concatenate([np.array(df['id'], dtype=np.int64).reshape(df.shape[0],1), gru_feature_2, gru_feature_1], axis=1)\n",
    "gru_feature_df = pd.DataFrame(gru_feature, columns=['id', 'GRU_predict']+['GRU_feature_'+str(i+1) for i in range(gru_feature_1.shape[1])])\n",
    "gru_feature_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5d3eb4-6770-4c67-98c9-743eb99cb2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_signal_col = []\n",
    "for i in range(1024):\n",
    "    if np.std(gru_feature_df['GRU_feature_'+str(i+1)]) < 0.01:\n",
    "        no_signal_col.append('GRU_feature_'+str(i+1))\n",
    "\n",
    "print( len(no_signal_col) )\n",
    "\n",
    "gru_feature_df = gru_feature_df[[x for x in gru_feature_df.columns if x not in no_signal_col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7f78aa-ff87-408c-babd-79ac89833bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_feature_df[['id','GRU_predict']].to_csv('../data/GRU_features_predict_only.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
