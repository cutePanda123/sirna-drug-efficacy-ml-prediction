{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dad37069-2a81-4810-9d15-0f5a3e8e8190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from rich import print\n",
    "from sklearn.metrics import precision_score, recall_score, mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca8cdcc0-520c-4f09-af0e-ed8b5f29c131",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GenomicTokenizer:\n",
    "    def __init__(self, ngram=5, stride=2):\n",
    "        self.ngram = ngram\n",
    "        self.stride = stride\n",
    "        \n",
    "    def tokenize(self, t):\n",
    "        t = t.upper()\n",
    "        if self.ngram == 1:\n",
    "            toks = list(t)\n",
    "        else:\n",
    "            toks = [t[i:i+self.ngram] for i in range(0, len(t), self.stride) if len(t[i:i+self.ngram]) == self.ngram]\n",
    "        if len(toks[-1]) < self.ngram:\n",
    "            toks = toks[:-1]\n",
    "        return toks\n",
    "\n",
    "\n",
    "class GenomicVocab:\n",
    "    def __init__(self, itos):\n",
    "        self.itos = itos\n",
    "        self.stoi = {v:k for k,v in enumerate(self.itos)}\n",
    "        \n",
    "    @classmethod\n",
    "    def create(cls, tokens, max_vocab, min_freq):\n",
    "        freq = Counter(tokens)\n",
    "        itos = ['<pad>'] + [o for o,c in freq.most_common(max_vocab-1) if c >= min_freq]\n",
    "        return cls(itos)\n",
    "\n",
    "\n",
    "class SiRNADataset(Dataset):\n",
    "    def __init__(self, df, columns, vocab, tokenizer, max_len):\n",
    "        self.df = df\n",
    "        self.columns = columns\n",
    "        self.vocab = vocab\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        seqs = [self.tokenize_and_encode(row[col]) for col in self.columns]\n",
    "        target = torch.tensor(row['mRNA_remaining_pct'], dtype=torch.float)\n",
    "\n",
    "        return seqs, target\n",
    "\n",
    "    def tokenize_and_encode(self, seq):\n",
    "        if ' ' in seq:  # Modified sequence\n",
    "            tokens = seq.split()\n",
    "        else:  # Regular sequence\n",
    "            tokens = self.tokenizer.tokenize(seq)\n",
    "        \n",
    "        encoded = [self.vocab.stoi.get(token, 0) for token in tokens]  # Use 0 (pad) for unknown tokens\n",
    "        padded = encoded + [0] * (self.max_len - len(encoded))\n",
    "        return torch.tensor(padded[:self.max_len], dtype=torch.long)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9781f900-0f79-4e73-8381-23b49b0ef3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SiRNAModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=200, hidden_dim=256, n_layers=3, dropout=0.5):\n",
    "        super(SiRNAModel, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.gru = nn.GRU(embed_dim, hidden_dim, n_layers, bidirectional=True, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 4, 1) # Bi-direactional and two feature columns\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embedded = [self.embedding(seq) for seq in x]\n",
    "        outputs = []\n",
    "        for embed in embedded:\n",
    "            x, _ = self.gru(embed)\n",
    "            x = self.dropout(x[:, -1, :])  # Use last hidden state\n",
    "            outputs.append(x)\n",
    "        \n",
    "        x = torch.cat(outputs, dim=1)\n",
    "        x = self.fc(x)\n",
    "        return x.squeeze()\n",
    "\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, threshold=30):\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "    y_true_binary = (y_true < threshold).astype(int)\n",
    "    y_pred_binary = (y_pred < threshold).astype(int)\n",
    "\n",
    "    mask = (y_pred >= 0) & (y_pred <= threshold)\n",
    "    range_mae = mean_absolute_error(y_true[mask], y_pred[mask]) if mask.sum() > 0 else 100\n",
    "\n",
    "    precision = precision_score(y_true_binary, y_pred_binary, average='binary')\n",
    "    recall = recall_score(y_true_binary, y_pred_binary, average='binary')\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    score = (1 - mae / 100) * 0.5 + (1 - range_mae / 100) * f1 * 0.5\n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=50, device='cuda'):\n",
    "    model.to(device)\n",
    "    best_score = -float('inf')\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for inputs, targets in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "            inputs = [x.to(device) for x in inputs]\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_preds = []\n",
    "        val_targets = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs = [x.to(device) for x in inputs]\n",
    "                targets = targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "                val_preds.extend(outputs.cpu().numpy())\n",
    "                val_targets.extend(targets.cpu().numpy())\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        val_preds = np.array(val_preds)\n",
    "        val_targets = np.array(val_targets)\n",
    "        score = calculate_metrics(val_targets, val_preds)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print(f'Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "        print(f'Learning Rate: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "        print(f'Validation Score: {score:.4f}')\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_model = model.state_dict().copy()\n",
    "            print(f'New best model found with socre: {best_score:.4f}')\n",
    "\n",
    "    return best_model\n",
    "\n",
    "def evaluate_model(model, test_loader, device='cuda'):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, target in test_loader:\n",
    "            inputs = [x.to(device) for x in inputs]\n",
    "            outputs = model(inputs)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            targets.extend(target.numpy())\n",
    "\n",
    "    y_pred = np.array(predictions)\n",
    "    y_test = np.array(targets)\n",
    "    \n",
    "    score = calculate_metrics(y_test, y_pred)\n",
    "    print(f\"Test Score: {score:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "777a69f5-a808-48bf-a3fc-2be22197b56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Load data\n",
    "train_data = pd.read_csv('../train_data.csv')\n",
    "columns = ['siRNA_antisense_seq', 'modified_siRNA_antisense_seq_list']\n",
    "\n",
    "train_data.dropna(subset=columns + ['mRNA_remaining_pct'], inplace=True)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.1, random_state=42)\n",
    "\n",
    "# Create vocabulary\n",
    "tokenizer = GenomicTokenizer(ngram=3, stride=1)\n",
    "\n",
    "all_tokens = []\n",
    "for col in columns:\n",
    "    for seq in train_data[col]:\n",
    "        if ' ' in seq:  # Modified sequence\n",
    "            all_tokens.extend(seq.split())\n",
    "        else:\n",
    "            all_tokens.extend(tokenizer.tokenize(seq))\n",
    "vocab = GenomicVocab.create(all_tokens, max_vocab=10000, min_freq=1)\n",
    "\n",
    "# Find max sequence length (==25 in this case)\n",
    "max_len = max(max(len(seq.split()) if ' ' in seq else len(tokenizer.tokenize(seq)) \n",
    "                    for seq in train_data[col]) for col in columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82c48dfb-a537-4042-b770-c07f3bec0846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SiRNAModel(\n",
       "  (embedding): Embedding(92, 200, padding_idx=0)\n",
       "  (gru): GRU(200, 256, num_layers=3, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (fc): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Load trained GRU model\n",
    "gru_model = SiRNAModel(92)\n",
    "gru_model.load_state_dict(torch.load('../GRU_weights')) # Trained GRU model\n",
    "gru_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49c954d3-d17d-4a54-8380-094fb45b1be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_original = pd.read_csv(\"../train_data.csv\")\n",
    "n_original = df_original.shape[0]\n",
    "df_submit = pd.read_csv(\"../sample_submission.csv\")\n",
    "df = pd.concat([df_original, df_submit], axis=0).reset_index(drop=True)\n",
    "\n",
    "all_dataset = SiRNADataset(df, columns, vocab, tokenizer, max_len)\n",
    "all_loader = DataLoader(all_dataset, batch_size=df.shape[0], shuffle=False)\n",
    "for x, y in all_loader:\n",
    "    None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27ff4c59-822b-4932-be96-9330654ffe6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "def get_GRU_output(x, model):\n",
    "    model.eval()\n",
    "    temp1 = model._modules['embedding'](x[0])\n",
    "    temp2 = model._modules['embedding'](x[1])\n",
    "    temp1, _ = model._modules['gru'](temp1)\n",
    "    temp2, _ = model._modules['gru'](temp2)\n",
    "    retval = torch.cat([temp1[:, -1, :], temp2[:, -1, :]], dim=1)\n",
    "    return retval\n",
    "\n",
    "gru_feature_1 = np.zeros((df.shape[0], 1024))\n",
    "gru_feature_2 = np.zeros((df.shape[0], 1))\n",
    "\n",
    "for i in range(0, len(y), 100):\n",
    "    with torch.no_grad():\n",
    "        temp_x = [x[0][i:(i+100)], x[1][i:(i+100)]]\n",
    "        gru_feature_2[i:(i+100),0] = gru_model(temp_x)\n",
    "        temp = get_GRU_output(temp_x, gru_model)\n",
    "        gru_feature_1[i:(i+100)] = np.array(temp)\n",
    "        # print(temp.shape)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4e596c4-7ca7-4e95-9909-726b65341fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>GRU_predict</th>\n",
       "      <th>GRU_feature_1</th>\n",
       "      <th>GRU_feature_2</th>\n",
       "      <th>GRU_feature_3</th>\n",
       "      <th>GRU_feature_4</th>\n",
       "      <th>GRU_feature_5</th>\n",
       "      <th>GRU_feature_6</th>\n",
       "      <th>GRU_feature_7</th>\n",
       "      <th>GRU_feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>GRU_feature_1015</th>\n",
       "      <th>GRU_feature_1016</th>\n",
       "      <th>GRU_feature_1017</th>\n",
       "      <th>GRU_feature_1018</th>\n",
       "      <th>GRU_feature_1019</th>\n",
       "      <th>GRU_feature_1020</th>\n",
       "      <th>GRU_feature_1021</th>\n",
       "      <th>GRU_feature_1022</th>\n",
       "      <th>GRU_feature_1023</th>\n",
       "      <th>GRU_feature_1024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>33.832245</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-3.731370e-03</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>-0.999999</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.192093e-07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999999</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.678871</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.010479</td>\n",
       "      <td>0.999814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.0</td>\n",
       "      <td>30.202850</td>\n",
       "      <td>-0.214032</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-6.271336e-01</td>\n",
       "      <td>-0.046766</td>\n",
       "      <td>0.040665</td>\n",
       "      <td>-0.999848</td>\n",
       "      <td>-9.706432e-02</td>\n",
       "      <td>0.882791</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.001998</td>\n",
       "      <td>-0.999935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.0</td>\n",
       "      <td>34.311020</td>\n",
       "      <td>-0.997860</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>8.344650e-07</td>\n",
       "      <td>-0.994178</td>\n",
       "      <td>-0.999998</td>\n",
       "      <td>-0.999971</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999996</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.820488</td>\n",
       "      <td>-0.999999</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.052048</td>\n",
       "      <td>0.999945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.0</td>\n",
       "      <td>60.863113</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-5.203009e-02</td>\n",
       "      <td>-0.959726</td>\n",
       "      <td>-0.009937</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-6.341934e-05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998358</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>1.490116e-05</td>\n",
       "      <td>-0.991066</td>\n",
       "      <td>-0.999998</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.192093e-07</td>\n",
       "      <td>-6.451774e-01</td>\n",
       "      <td>0.009498</td>\n",
       "      <td>-0.999946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>22.256744</td>\n",
       "      <td>-0.001306</td>\n",
       "      <td>-0.990601</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.005046</td>\n",
       "      <td>-0.738691</td>\n",
       "      <td>8.090854e-03</td>\n",
       "      <td>0.061507</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.991022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>-0.999841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30651</th>\n",
       "      <td>59038.0</td>\n",
       "      <td>24.268742</td>\n",
       "      <td>-0.068692</td>\n",
       "      <td>-0.907492</td>\n",
       "      <td>-2.798337e-02</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.999626</td>\n",
       "      <td>-1.144409e-05</td>\n",
       "      <td>0.975849</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999998</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.019696</td>\n",
       "      <td>-0.999973</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.091423</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30652</th>\n",
       "      <td>59042.0</td>\n",
       "      <td>45.576744</td>\n",
       "      <td>-0.270773</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-9.663385e-01</td>\n",
       "      <td>-0.162008</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.999982</td>\n",
       "      <td>-1.192093e-07</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999938</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>4.768372e-07</td>\n",
       "      <td>-0.998831</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.455724e-03</td>\n",
       "      <td>0.064839</td>\n",
       "      <td>-0.999992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30653</th>\n",
       "      <td>59050.0</td>\n",
       "      <td>88.484909</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-2.801418e-06</td>\n",
       "      <td>-0.212895</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.943111e-05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.922921</td>\n",
       "      <td>0.006740</td>\n",
       "      <td>1.192027e-02</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999826</td>\n",
       "      <td>-0.999891</td>\n",
       "      <td>-6.580353e-05</td>\n",
       "      <td>-2.756112e-01</td>\n",
       "      <td>0.890531</td>\n",
       "      <td>-0.997934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30654</th>\n",
       "      <td>59052.0</td>\n",
       "      <td>28.083324</td>\n",
       "      <td>-0.023629</td>\n",
       "      <td>-0.999626</td>\n",
       "      <td>-5.207360e-03</td>\n",
       "      <td>-0.000332</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>0.999846</td>\n",
       "      <td>8.344650e-07</td>\n",
       "      <td>0.026372</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999997</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.192093e-07</td>\n",
       "      <td>0.042450</td>\n",
       "      <td>-0.977028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30655</th>\n",
       "      <td>59058.0</td>\n",
       "      <td>41.245792</td>\n",
       "      <td>-0.994633</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.499891e-03</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>8.344650e-07</td>\n",
       "      <td>0.998873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995926</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.279742</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>0.033385</td>\n",
       "      <td>-0.999713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30656 rows × 1026 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  GRU_predict  GRU_feature_1  GRU_feature_2  GRU_feature_3  \\\n",
       "0          7.0    33.832245      -1.000000      -1.000000  -3.731370e-03   \n",
       "1         16.0    30.202850      -0.214032      -1.000000  -6.271336e-01   \n",
       "2         17.0    34.311020      -0.997860      -1.000000   8.344650e-07   \n",
       "3         22.0    60.863113      -1.000000      -1.000000  -5.203009e-02   \n",
       "4         35.0    22.256744      -0.001306      -0.990601  -1.000000e+00   \n",
       "...        ...          ...            ...            ...            ...   \n",
       "30651  59038.0    24.268742      -0.068692      -0.907492  -2.798337e-02   \n",
       "30652  59042.0    45.576744      -0.270773      -1.000000  -9.663385e-01   \n",
       "30653  59050.0    88.484909       0.999995      -1.000000  -2.801418e-06   \n",
       "30654  59052.0    28.083324      -0.023629      -0.999626  -5.207360e-03   \n",
       "30655  59058.0    41.245792      -0.994633      -1.000000  -1.499891e-03   \n",
       "\n",
       "       GRU_feature_4  GRU_feature_5  GRU_feature_6  GRU_feature_7  \\\n",
       "0          -0.000202      -0.999999      -1.000000  -1.192093e-07   \n",
       "1          -0.046766       0.040665      -0.999848  -9.706432e-02   \n",
       "2          -0.994178      -0.999998      -0.999971   0.000000e+00   \n",
       "3          -0.959726      -0.009937      -1.000000  -6.341934e-05   \n",
       "4          -0.000002       0.005046      -0.738691   8.090854e-03   \n",
       "...              ...            ...            ...            ...   \n",
       "30651      -0.001813       0.000003      -0.999626  -1.144409e-05   \n",
       "30652      -0.162008      -0.000003      -0.999982  -1.192093e-07   \n",
       "30653      -0.212895      -1.000000      -1.000000   1.943111e-05   \n",
       "30654      -0.000332      -0.000034       0.999846   8.344650e-07   \n",
       "30655       0.000405       0.000604      -1.000000   8.344650e-07   \n",
       "\n",
       "       GRU_feature_8  ...  GRU_feature_1015  GRU_feature_1016  \\\n",
       "0           1.000000  ...         -0.999999          0.000001   \n",
       "1           0.882791  ...         -0.999901          0.000000   \n",
       "2           1.000000  ...         -0.999996          0.000019   \n",
       "3           1.000000  ...          0.998358          0.000583   \n",
       "4           0.061507  ...         -0.991022          0.000000   \n",
       "...              ...  ...               ...               ...   \n",
       "30651       0.975849  ...         -0.999998          0.000095   \n",
       "30652       0.999949  ...          0.999938          0.000108   \n",
       "30653       1.000000  ...          0.922921          0.006740   \n",
       "30654       0.026372  ...         -0.999997          0.000004   \n",
       "30655       0.998873  ...          0.995926          0.000001   \n",
       "\n",
       "       GRU_feature_1017  GRU_feature_1018  GRU_feature_1019  GRU_feature_1020  \\\n",
       "0          0.000000e+00          0.678871         -1.000000         -1.000000   \n",
       "1          0.000000e+00          0.999990         -1.000000         -1.000000   \n",
       "2          0.000000e+00          0.820488         -0.999999         -1.000000   \n",
       "3          1.490116e-05         -0.991066         -0.999998         -1.000000   \n",
       "4          0.000000e+00          1.000000         -1.000000         -1.000000   \n",
       "...                 ...               ...               ...               ...   \n",
       "30651      0.000000e+00          0.019696         -0.999973         -1.000000   \n",
       "30652      4.768372e-07         -0.998831         -1.000000         -1.000000   \n",
       "30653      1.192027e-02         -1.000000         -0.999826         -0.999891   \n",
       "30654      0.000000e+00          0.999980         -1.000000         -1.000000   \n",
       "30655      0.000000e+00         -0.279742         -1.000000         -1.000000   \n",
       "\n",
       "       GRU_feature_1021  GRU_feature_1022  GRU_feature_1023  GRU_feature_1024  \n",
       "0          0.000000e+00      0.000000e+00          0.010479          0.999814  \n",
       "1          0.000000e+00      0.000000e+00          0.001998         -0.999935  \n",
       "2          0.000000e+00      0.000000e+00          0.052048          0.999945  \n",
       "3         -1.192093e-07     -6.451774e-01          0.009498         -0.999946  \n",
       "4          0.000000e+00      0.000000e+00          0.001862         -0.999841  \n",
       "...                 ...               ...               ...               ...  \n",
       "30651      0.000000e+00      0.000000e+00          0.091423          0.999998  \n",
       "30652      0.000000e+00     -1.455724e-03          0.064839         -0.999992  \n",
       "30653     -6.580353e-05     -2.756112e-01          0.890531         -0.997934  \n",
       "30654      0.000000e+00     -1.192093e-07          0.042450         -0.977028  \n",
       "30655      0.000000e+00     -9.536743e-07          0.033385         -0.999713  \n",
       "\n",
       "[30656 rows x 1026 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_feature = np.concatenate([np.array(df['id'], dtype=np.int64).reshape(df.shape[0],1), gru_feature_2, gru_feature_1], axis=1)\n",
    "gru_feature_df = pd.DataFrame(gru_feature, columns=['id', 'GRU_predict']+['GRU_feature_'+str(i+1) for i in range(gru_feature_1.shape[1])])\n",
    "gru_feature_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc5d3eb4-6770-4c67-98c9-743eb99cb2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">76</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m76\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "no_signal_col = []\n",
    "for i in range(1024):\n",
    "    if np.std(gru_feature_df['GRU_feature_'+str(i+1)]) < 0.01:\n",
    "        no_signal_col.append('GRU_feature_'+str(i+1))\n",
    "\n",
    "print( len(no_signal_col) )\n",
    "\n",
    "gru_feature_df = gru_feature_df[[x for x in gru_feature_df.columns if x not in no_signal_col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d7f78aa-ff87-408c-babd-79ac89833bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gru_feature_df.to_csv('../GRU_features.csv', index=False)\n",
    "gru_feature_df[['id','GRU_predict']].to_csv('../GRU_features_predict_only.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e167973-6955-4cb1-8cf4-48877dde4bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de047de7-3f6d-4415-ba0f-700ab6ff6ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b03185-6fa5-425b-a1bb-2d448ad08d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294420ce-fbb7-4d99-a679-b0439ca9dc28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c328127d-ae4f-40f7-95a7-26673d8dccbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
